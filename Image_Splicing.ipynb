{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Splicing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VqcB61mH2L2dk7fNHJlBmhUmSGrGdySj",
      "authorship_tag": "ABX9TyOxXjBHPV+tMjgLCYpYlqbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsAksht/testing/blob/master/Image_Splicing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOGrmCI7h53g",
        "outputId": "e0cf7a6c-8317-4b51-c3ef-76b3e527cc49"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing import text\n",
        "# Get a ResNet50 model\n",
        "\n",
        "\n",
        "def resnet50_model(classes=2, *args, **kwargs):\n",
        "    # Load a model if we have saved one\n",
        "    if(os.path.isfile('/content/drive/MyDrive/resnet_50.h5') == True):\n",
        "        return keras.models.load_model('/content/drive/MyDrive/resnet_50.h5')\n",
        "    # Create an input layer\n",
        "    input = keras.layers.Input(shape=(None, None, 3))\n",
        "    # Create output layers\n",
        "    output = keras.layers.ZeroPadding2D(padding=3, name='padding_conv1')(input)\n",
        "    output = keras.layers.Conv2D(64, (7, 7), strides=(\n",
        "        2, 2), use_bias=False, name='conv1')(output)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, epsilon=1e-5, name='bn_conv1')(output)\n",
        "    output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "    output = keras.layers.MaxPooling2D((3, 3), strides=(\n",
        "        2, 2), padding='same', name='pool1')(output)\n",
        "    output = conv_block(output, 3, [64, 64, 256],\n",
        "                        stage=2, block='a', strides=(1, 1))\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "    output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "    output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    output = keras.layers.GlobalAveragePooling2D(name='pool5')(output)\n",
        "    output = keras.layers.Dense(\n",
        "        classes, activation='softmax', name='fc1000')(output)\n",
        "    # Create a model from input layer and output layers\n",
        "    model = keras.models.Model(inputs=input, outputs=output, *args, **kwargs)\n",
        "    # Print model\n",
        "    print()\n",
        "    print(model.summary(), '\\n')\n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam', metrics=['accuracy'])\n",
        "    # Return a model\n",
        "    return model\n",
        "# Create an identity block\n",
        "\n",
        "\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "\n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create layers\n",
        "    output = keras.layers.Conv2D(\n",
        "        filters1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                                 kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(\n",
        "        filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2c')(output)\n",
        "    output = keras.layers.add([output, input])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "# Create a convolution block\n",
        "\n",
        "\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create block layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), strides=strides,\n",
        "                                 kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same',\n",
        "                                 kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(\n",
        "        filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '2c')(output)\n",
        "    shortcut = keras.layers.Conv2D(filters3, (1, 1), strides=strides,\n",
        "                                   kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "    shortcut = keras.layers.BatchNormalization(\n",
        "        axis=3, name=bn_name_base + '1')(shortcut)\n",
        "    output = keras.layers.add([output, shortcut])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "# Train a model\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Variables, 25 epochs so far\n",
        "    epochs = 1\n",
        "    batch_size = 32\n",
        "    train_samples = 2 * 4999  # 10 categories with 5000 images in each category\n",
        "    img_width, img_height = 32, 32\n",
        "    model = resnet50_model(2)\n",
        "    train_data_generator = keras.preprocessing.image.ImageDataGenerator()\n",
        "    train_generator = train_data_generator.flow_from_directory('/content/drive/MyDrive/CASIA5', target_size=(img_width, img_height), batch_size=batch_size,\n",
        "                                                               color_mode='rgb',\n",
        "                                                               shuffle=True,\n",
        "                                                               class_mode='categorical')\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_samples // batch_size,\n",
        "        epochs=epochs)\n",
        "    model.save('/content/drive/MyDrive/resnet_50_1.h5')\n",
        "    print('Saved model to disk!')\n",
        "    labels = train_generator.class_indices\n",
        "    classes = {}\n",
        "    for key, value in labels.items():\n",
        "        classes[value] = key.capitalize()\n",
        "    with open('/content/drive/MyDrive/classes.pkl', 'wb') as file:\n",
        "        pickle.dump(classes, file)\n",
        "    print('Saved classes to disk!')\n",
        "\n",
        "\n",
        "def main():\n",
        "    train()\n",
        "\n",
        "\n",
        "# Tell python to run main method\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9998 images belonging to 2 classes.\n",
            "312/312 [==============================] - 5275s 17s/step - loss: 0.6129 - accuracy: 0.6701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk!\n",
            "Saved classes to disk!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zJJ-3O736h2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}